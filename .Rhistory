# new_c[i] stays 0 or 1/6
}
}
return(data.frame(
a1 = new_a1,
b1 = new_b1,
c = new_c,
voxel = meta_df$voxel,
subject = meta_df$subject,
mask = meta_df$mask
))
}
new_params_df <- round_regularized_params(model_outputs, "A")
# Replace the plotting code with this section
# Function to compute frequency of (a1, b1) combinations
compute_frequency <- function(df) {
df %>%
group_by(a1, b1, c) %>%
summarise(Frequency = n(), .groups = "drop")
}
# Compute frequency tables for both datasets
freq_best <- compute_frequency(best_params_df)
freq_new <- compute_frequency(new_params_df)
# Ensure same color scale by finding global frequency range
max_freq <- max(c(freq_best$Frequency, freq_new$Frequency))
# Function to create faceted heatmap
create_faceted_heatmap <- function(data, title) {
# Convert c values to descriptive labels
data <- data %>%
mutate(c_label = ifelse(near(c, 0), "No Undershoot (c=0)",
ifelse(near(c, 1/6), "With Undershoot (c=1/6)",
paste0("c=", c))))
ggplot(data, aes(x = factor(a1), y = factor(b1), fill = Frequency)) +
geom_tile() +
geom_text(aes(label = Frequency), color = "black", size = 3) +
scale_fill_gradient(low = "purple", high = "yellow", limits = c(0, max_freq)) +
facet_wrap(~ c_label, ncol = 1) +
labs(title = title, x = "a1", y = "b1", fill = "Frequency") +
theme_classic() +
theme(
strip.background = element_rect(fill = "lightgray"),
strip.text = element_text(face = "bold", size = 12)
)
}
# Create the heatmaps
best_plot <- create_faceted_heatmap(freq_best, "Best Parameters Frequency")
new_plot <- create_faceted_heatmap(freq_new, "New Parameters Frequency")
# Save the plots to separate files
best_plot_fname <- file.path(plot_dir, '3_Regularize', 'G_variance', 'HRF_regularize_plots',
paste0(sess_g, '_best_params_heatmap.png'))
new_plot_fname <- file.path(plot_dir, '3_Regularize', 'G_variance', 'HRF_regularize_plots',
paste0( sess_g, '_new_params_heatmap.png'))
# Create directories if they don't exist
if (!dir.exists(dirname(best_plot_fname))) {
dir.create(dirname(best_plot_fname), recursive = TRUE, showWarnings = FALSE)
}
# Save plots with appropriate dimensions
ggsave(best_plot_fname, best_plot, width = 10, height = 8, dpi = 300)
ggsave(new_plot_fname, new_plot, width = 10, height = 8, dpi = 300)
for(t in 1:3){
for(r in 1:2){
sess <- paste(sess_names[t], run_names[r], sep='_')
### Loop over GLM types considered in "All HRFs" step (fitting many HRFs based on parameter grid)
glm_names <- c('base','on','onoff')
if(t==3){ glm_names <- c('base') } #since gambling is event-related, no onsets/offsets
for (name_g in glm_names){
print(paste0("~~~~~~~~~ Preparing plots for ", sess," (", name_g, ") ~~~~~~~~~~~~~"))
sess_g <- paste0(sess,'_',name_g)
file_path <- file.path(main_dir, "results", "2_allHRFs", paste0(sess_g, ".RData"))
load(file_path) #best_params_df
file_path <- file.path(result_dir, '3_regularize', paste0(sess_g, '_HRF_regularize_df', '.RData'))
load(file_path) #HRF_regularize_large_df -> final predictions, final population effects, final subject-level effects, iterations
results <- model_outputs # from load()
new_params_df <- round_regularized_params(model_outputs, "A")
# Removed Filter logic for params which is duplicate as we have Euclidean Distance implemented in rounding
# [TODO] Delete outofrange files from github which were generated by filter logic
# Replace the plotting code with this section
# Function to compute frequency of (a1, b1) combinations
compute_frequency <- function(df) {
df %>%
group_by(a1, b1, c) %>%
summarise(Frequency = n(), .groups = "drop")
}
# Compute frequency tables for both datasets
freq_best <- compute_frequency(best_params_df)
freq_new <- compute_frequency(new_params_df)
# Ensure same color scale by finding global frequency range
max_freq <- max(c(freq_best$Frequency, freq_new$Frequency))
# Function to create faceted heatmap
create_faceted_heatmap <- function(data, title) {
# Convert c values to descriptive labels
data <- data %>%
mutate(c_label = ifelse(near(c, 0), "No Undershoot (c=0)",
ifelse(near(c, 1/6), "With Undershoot (c=1/6)",
paste0("c=", c))))
ggplot(data, aes(x = factor(a1), y = factor(b1), fill = Frequency)) +
geom_tile() +
geom_text(aes(label = Frequency), color = "black", size = 3) +
scale_fill_gradient(low = "purple", high = "yellow", limits = c(0, max_freq)) +
facet_wrap(~ c_label, ncol = 1) +
labs(title = title, x = "a1", y = "b1", fill = "Frequency") +
theme_classic() +
theme(
strip.background = element_rect(fill = "lightgray"),
strip.text = element_text(face = "bold", size = 12)
)
}
# Create the heatmaps
best_plot <- create_faceted_heatmap(freq_best, "Best Parameters Frequency")
new_plot <- create_faceted_heatmap(freq_new, "New Parameters Frequency")
# Save the plots to separate files
best_plot_fname <- file.path(plot_dir, '3_Regularize', 'G_variance', 'HRF_regularize_plots',
paste0(sess_g, '_best_params_heatmap.png'))
new_plot_fname <- file.path(plot_dir, '3_Regularize', 'G_variance', 'HRF_regularize_plots',
paste0( sess_g, '_new_params_heatmap.png'))
# Create directories if they don't exist
if (!dir.exists(dirname(best_plot_fname))) {
dir.create(dirname(best_plot_fname), recursive = TRUE, showWarnings = FALSE)
}
# Save plots with appropriate dimensions
ggsave(best_plot_fname, best_plot, width = 10, height = 8, dpi = 300)
ggsave(new_plot_fname, new_plot, width = 10, height = 8, dpi = 300)
}
}
}
### LIBRARIES AND SETUP --------------------------------------------------------
source("~/Documents/Github/HRF-Adaptation-paper/Code/0_Setup_Libraries.R", local = FALSE, echo=TRUE)
ciftiTools::ciftiTools.setOption('wb_path','/Applications')
load("~/Documents/Github/HRF-Adaptation-paper/Code/0_Setup.RData")
#for HRF() function
library(hrf)
main_dir <- '~/Documents/GitHub/HRF-Adaptation-paper'
result_dir <- file.path(main_dir,'results','2_allHRFs')
plot_dir <- file.path(main_dir, 'plots','2_allHRFs')
#canonical
a1_spm <- 6 #seconds
b1_spm <- 1 #seconds
c_spm <- 1/6 #relative scale of undershoot
a1 <- seq(a1_spm/2, a1_spm*2, by=1)
b1 <- seq(b1_spm/2, b1_spm*2, by=0.25)
hrf_params <- expand.grid(a1 = a1,
b1 = b1,
TR=c(0.72, 2))
#calculate time to peak
hrf_params$shape1 <- hrf_params$a1/hrf_params$b1
hrf_params$rate1 <- hrf_params$TR/hrf_params$b1
hrf_params$TRs_to_peak <- (hrf_params$shape1 - 1)/(hrf_params$rate1) #mode of the first Gamma, in terms of seconds
hrf_params$time_to_peak <- hrf_params$TRs_to_peak * hrf_params$TR #convert to seconds
hrf_params$a2 <- (16/sqrt(6))*sqrt(hrf_params$a1)*sqrt(hrf_params$b1)
hrf_params$b2 <- hrf_params$b1
#exclude HRFs that peak faster than 2s
hrf_params <- hrf_params[hrf_params$time_to_peak >= 2,] #min timing of response
a1_grid <- c(2,a1) + 0.5
b1_grid <- c(0.25,b1) + 0.25/2
pdf(file.path(plot_dir,'param_grid_all_byTR.pdf'), width=9, height=6)
main_dir
plot_path <- normalizePath("~/Documents/GitHub/HRF-Adaptation-paper/plots/2_allHRFs", mustWork = FALSE)
pdf(file.path(plot_path, "param_grid_all_byTR.pdf"), width = 9, height = 6)
pdf(file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/plots/2_allHRFs','param_grid_all_byTR.pdf'), width=9, height=6)
ggplot(hrf_params, aes(x=a1, y=b1, fill=time_to_peak)) +
geom_hline(yintercept = b1_grid, alpha=0.1) +
geom_vline(xintercept = a1_grid, alpha=0.1) +
geom_tile(alpha=0.8) +
geom_text(aes(label=round(time_to_peak, 1))) +
scale_fill_viridis_c(option = 'C') +
scale_x_continuous(breaks=a1) + scale_y_continuous(breaks=b1) +
theme_few() + theme(legend.position='bottom') +
facet_grid(. ~ TR, labeller = 'label_both')
dev.off()
#we get the same result with TR=0.72 and TR=2
hrf_params <- subset(hrf_params, TR==2)
TR <- 2
vols <- seq(1:40) #this is in TRs
inds <- seq(1/100, 20, 1/100) * TR #upsample 100x for smoother plots and more precise FWHM
nt <- length(inds)
hrf_df <- data.frame(a1 = rep(hrf_params$a1, each=nt),
b1 = rep(hrf_params$b1, each=nt),
TR = TR,
sec = inds) #will be recycled
hrf_df$a2 <- (16/sqrt(6))*sqrt(hrf_df$a1)*sqrt(hrf_df$b1)
hrf_df$b2 <- hrf_df$b1
hrf_df$c <- c_spm
#also consider no undershoot to allow for longer responses
hrf_df2 <- hrf_df; hrf_df2$c <- 0
hrf_df <- rbind(hrf_df, hrf_df2)
hrf_params$c <- c_spm
hrf_params2 <- hrf_params; hrf_params2$c <- 0
hrf_params <- rbind(hrf_params, hrf_params2)
#store FWHM and time to resolve
hrf_params$FWHM <- hrf_params$time_to_end <- NA
hrf_df$FWHM <- hrf_df$time_to_end <- NA
#loop over parameter combinations
hrf_df$HRF <- NA # hrf_df$dHRF <- hrf_df$ddHRF <- NA
for(ii in 1:nrow(hrf_params)){
a1_ii <- hrf_params$a1[ii]
b1_ii <- hrf_params$b1[ii]
#a2_ii <- hrf_params$a2[ii]
a2_ii <- 16/sqrt(6)*sqrt(a1_ii*b1_ii)
c_ii <- hrf_params$c[ii]
hrf_ii <- hrf::HRF_calc(t = inds, deriv=0, a1 = a1_ii, b1 = b1_ii, a2 = a2_ii, c = c_ii) #this is in super-resolution
#determine FWHM
peak_val <- max(hrf_ii)
vals_left <- hrf_ii[1:which.max(hrf_ii)]
vals_right <- hrf_ii[which.max(hrf_ii):length(hrf_ii)]
x1 <- min(which(vals_left > 0.5*peak_val)) #first time point before peak that exceeds half-maximum
x2 <- max(which(vals_right > 0.5*peak_val)) #last time point after peak that exceeds half-maximum
time1 <- inds[x1] #in seconds
time2 <- inds[which.max(hrf_ii) + x2 - 1] #in seconds
hrf_params$FWHM[ii] <- time2 - time1
#determine when the HRF fully resolves
if(c_ii > 0) peak2 <- which.min(hrf_ii) else peak2 <- which.max(hrf_ii) #if no undershoot, consider everything following the peak
vals_right <- hrf_ii[peak2:length(hrf_ii)]
x3 <- min(which(abs(vals_right) < 0.07)) #point at which everything after is less than 7% of the peak
if(is.infinite(x3)) x3 <- length(vals_right) #set to equal the last index if HRF has not fully resolved
time_to_end_ii <- inds[peak2 + x3 - 1] #in seconds
hrf_params$time_to_end[ii] <- time_to_end_ii
rows_ii <- which(hrf_df$a1==a1_ii & hrf_df$b1==b1_ii & hrf_df$c==c_ii)
hrf_df$HRF[rows_ii] <- c(0,hrf_ii) #adding zero is a workaround since hrf_ii is missing one index
hrf_df$FWHM[rows_ii] <- time2 - time1
hrf_df$time_to_end[rows_ii] <- time_to_end_ii
}
save(hrf_df, hrf_params, file=file.path(result_dir, 'hrf_grid_all.RData'))
save(hrf_df, hrf_params, file=file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/results/2_allHRFs', 'hrf_grid_all.RData'))
load(file=file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/results/2_allHRFs', 'hrf_grid_all.RData'))
# Visualize HRFs
hrf_df$c_num <- hrf_df$c
hrf_df$c <- factor(hrf_df$c, levels = c(0, 1/6), labels=c('No Undershoot (c=0)', 'With Undershoot (c=1/6)'))
hrf_df$b1 <- paste0('b1 = ',hrf_df$b1)
pdf(file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/plots/2_allHRFs', 'HRFs_all.pdf'),width=8, height=10.5)
ggplot(hrf_df, aes(x=sec, y=HRF, color=a1, group=a1)) +
geom_vline(xintercept=c(2,10), linetype=2, color='gray') + #our limits on time to peak and undershoot
geom_hline(yintercept = 0, color='gray') +
geom_line() + xlim(0,30) +
scale_color_viridis_c(breaks=seq(3,12,3)) + scale_y_continuous(breaks=c(0,0.5,1)) +
facet_grid(b1 ~ c) +
theme_few() + theme(legend.position='bottom')
dev.off()
#exclude HRFs that resolve after more than 30s
pdf(file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/plots/2_allHRFs', 'HRFs_toolong.pdf'), width=8, height=10.5)
ggplot(hrf_df, aes(x=sec, y=HRF, color=(time_to_end > 30), group=a1)) +
geom_vline(xintercept=c(2,10), linetype=2, color='gray') + #our limits on time to peak and undershoot
geom_hline(yintercept = 0, color='gray') +
geom_line() + xlim(0,30) +
scale_color_manual(values = c('black','red')) + scale_y_continuous(breaks=c(0,0.5,1)) +
facet_grid(b1 ~ c) +
theme_few() + theme(legend.position='bottom')
dev.off()
hrf_params$c_label <- factor(hrf_params$c, levels = c(0, 1/6), labels=c('No Undershoot (c=0)', 'With Undershoot (c=1/6)'))
pdf(file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/plots/2_allHRFs', 'param_grid_all.pdf'), width=10, height=9)
p1 <- ggplot(hrf_params, aes(x=a1, y=b1, fill=time_to_peak)) +
geom_hline(yintercept = b1_grid, alpha=0.1) +
geom_vline(xintercept = a1_grid, alpha=0.1) +
geom_tile(alpha=0.8) +
geom_text(aes(label=round(time_to_peak, 1))) +
scale_fill_viridis_c('Time to Peak  ', option = 'C') +
scale_x_continuous(breaks=a1) + scale_y_continuous(breaks=b1) +
facet_grid(. ~ c_label) +
theme_few()
p2 <- ggplot(hrf_params, aes(x=a1, y=b1, fill=FWHM)) +
geom_hline(yintercept = b1_grid, alpha=0.1) +
geom_vline(xintercept = a1_grid, alpha=0.1) +
geom_tile(alpha=0.8) +
geom_text(aes(label=round(FWHM, 1))) +
scale_fill_viridis_c('Width (FWHM)', option = 'C') +
scale_x_continuous(breaks=a1) + scale_y_continuous(breaks=b1) +
facet_grid(. ~ c_label) +
theme_few()
grid.arrange(p1, p2, nrow=2)
dev.off()
pdf(file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/plots/2_allHRFs', 'param_grid.pdf'), width=8, height=10.5)
p1 <- ggplot(dplyr::filter(hrf_params, time_to_end <= 30), aes(x=a1, y=b1, fill=time_to_peak)) +
geom_hline(yintercept = b1_grid, alpha=0.1) +
geom_vline(xintercept = a1_grid, alpha=0.1) +
geom_tile(alpha=0.8) +
geom_text(aes(label=round(time_to_peak, 1))) +
scale_fill_viridis_c('Time to Peak\n', option = 'C') +
scale_x_continuous(breaks=a1) + scale_y_continuous(breaks=b1) +
facet_grid(. ~ c_label) + theme_few() + theme(legend.position='bottom')
p2 <- ggplot(dplyr::filter(hrf_params, time_to_end <= 30), aes(x=a1, y=b1, fill=FWHM)) +
geom_hline(yintercept = b1_grid, alpha=0.1) +
geom_vline(xintercept = a1_grid, alpha=0.1) +
geom_tile(alpha=0.8) +
geom_text(aes(label=round(FWHM, 1))) +
scale_fill_viridis_c('Width (FWHM)\n', option = 'D') +
scale_x_continuous(breaks=a1) + scale_y_continuous(breaks=b1) +
facet_grid(. ~ c_label) + theme_few() + theme(legend.position='bottom')
grid.arrange(p1, p2, nrow=2)
dev.off()
pdf(file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/plots/2_allHRFs', 'HRFs_final.pdf'), width=8, height=10.5)
ggplot(dplyr::filter(hrf_df, time_to_end <= 30), aes(x=sec, y=HRF, color=a1, group=a1)) +
geom_vline(xintercept=c(2,10), linetype=2, color='gray') + #our limits on time to peak and undershoot
geom_hline(yintercept = 0, color='gray') +
geom_line() + xlim(0,30) +
scale_color_viridis_c(breaks=seq(3,12,3)) + scale_y_continuous(breaks=c(0,0.5,1)) +
facet_grid(b1 ~ c) +
theme_few() + theme(legend.position='bottom')
dev.off()
hrf_params <- dplyr::filter(hrf_params, time_to_end <= 30)
save(hrf_params, file=file.path('/N/u/bhaveldi/Quartz/Documents/Github/HRF-Adaptation-paper/results/2_allHRFs','hrfParamGrid.RData'))
### LIBRARIES AND SETUP --------------------------------------------------------
source("~/Documents/Github/HRF-Adaptation-paper/Code/0_Setup_Libraries.R", local = FALSE, echo=TRUE)
load("~/Documents/Github/HRF-Adaptation-paper/Code/0_Setup.RData")
ciftiTools.setOption('wb_path','~/') #re-define wb_path because this code is run locally
xii <- readRDS(file = file.path(main_dir, 'Code', 'xii.rds'))
# Function to extract and round HRF parameters from a HRF_regularized results object.
round_regularized_params <- function(results, model = "A", inside_grid = TRUE) {
# Pick correct model based on selection
colname <- switch(model,
"A" = "param_pred_A",
"B" = "param_pred_B",
stop("Invalid model selection. Please choose 'A' or 'B'."))
# Load WLS values
df_a1 <- results$a1$results_WLS
df_b1 <- results$b1$results_WLS
df_c  <- results$c$results_WLS
a1_vals <- df_a1[[colname]]
b1_vals <- df_b1[[colname]]
c_vals  <- df_c[[colname]]
meta_df <- df_a1[, c("voxel", "subject", "mask")] # Voxel, subject, & mask are consistent across paramater data frames
# Round the values, some of these will be "off the grid" of accepted values
new_a1 <- round(a1_vals)   # a1: round to the nearest integer.
new_b1 <- round(b1_vals * 4) / 4  # b1: round to the nearest quarter.
new_c <- ifelse(abs(c_vals) <= abs(c_vals - (1/6)), 0, 1/6) # c: round to either 0 or 1/6, whichever is closer
# If we want to snap a1,b1,c values to acceptable values inside the grid,
# we'll compute the euclidean distance and find the closest point.
if (inside_grid) {
# Load acceptable values
load(file.path(main_dir, "results", "hrfParamGrid.RData"))
allowed_a1 <- hrf_params$a1
allowed_b1 <- hrf_params$b1
allowed_c  <- hrf_params$c
a_range <- max(allowed_a1, na.rm = TRUE) - min(allowed_a1, na.rm = TRUE)
b_range <- max(allowed_b1, na.rm = TRUE) - min(allowed_b1, na.rm = TRUE)
# loop over voxels and snap combinations based on shortest distance
# Should be O(n*m) where m is around around 50. Could potentially vectorize,
# but you trade memory constraints for a performance boost.
for (i in seq_along(new_a1)) {
sel <- which(allowed_c == new_c[i])       # only combos with same c
# Check if current (a1, b1) is already valid in allowed set for this c. if so then skip
valid_idx <- which(allowed_a1[sel] == new_a1[i] & allowed_b1[sel] == new_b1[i])
if (length(valid_idx) > 0) { next }
da  <- (new_a1[i] - allowed_a1[sel]) / a_range
db  <- (new_b1[i] - allowed_b1[sel]) / b_range
best <- sel[ which.min(da^2 + db^2) ]     # nearest by scaled distance
new_a1[i] <- allowed_a1[best]
new_b1[i] <- allowed_b1[best]
# new_c[i] stays 0 or 1/6
}
}
return(data.frame(
a1 = new_a1,
b1 = new_b1,
c = new_c,
voxel = meta_df$voxel,
subject = meta_df$subject,
mask = meta_df$mask
))
}
for(t in 1:3){
for(r in 1:2){
sess <- paste(sess_names[t], run_names[r], sep='_')
### Loop over GLM types considered in "All HRFs" step (fitting many HRFs based on parameter grid)
glm_names <- c('base','on','onoff')
if(t==3){ glm_names <- c('base') } #since gambling is event-related, no onsets/offsets
for (name_g in glm_names){
print(paste0("~~~~~~~~~ Preparing plots for ", sess," (", name_g, ") ~~~~~~~~~~~~~"))
sess_g <- paste0(sess,'_',name_g)
file_path <- file.path(main_dir, "results", "2_allHRFs", paste0(sess_g, ".RData"))
load(file_path) #best_params_df
file_path <- file.path(result_dir, '3_regularize', paste0(sess_g, '_HRF_regularize_df', '.RData'))
load(file_path) #HRF_regularize_large_df -> final predictions, final population effects, final subject-level effects, iterations
results <- model_outputs # from load()
new_params_df <- round_regularized_params(model_outputs, "A")
# Removed Filter logic for params which is duplicate as we have Euclidean Distance implemented in rounding
# [TODO] Delete outofrange files from github which were generated by filter logic
# Replace the plotting code with this section
# Function to compute frequency of (a1, b1) combinations
compute_frequency <- function(df) {
df %>%
group_by(a1, b1, c) %>%
summarise(Frequency = n(), .groups = "drop")
}
# Compute frequency tables for both datasets
freq_best <- compute_frequency(best_params_df)
freq_new <- compute_frequency(new_params_df)
# Ensure same color scale by finding global frequency range
max_freq <- max(c(freq_best$Frequency, freq_new$Frequency))
# Function to create faceted heatmap
create_faceted_heatmap <- function(data, title) {
# Convert c values to descriptive labels
data <- data %>%
mutate(c_label = ifelse(near(c, 0), "No Undershoot (c=0)",
ifelse(near(c, 1/6), "With Undershoot (c=1/6)",
paste0("c=", c))))
ggplot(data, aes(x = factor(a1), y = factor(b1), fill = Frequency)) +
geom_tile() +
geom_text(aes(label = Frequency), color = "black", size = 3) +
scale_fill_gradient(low = "purple", high = "yellow", limits = c(0, max_freq)) +
facet_wrap(~ c_label, ncol = 1) +
labs(title = title, x = "a1", y = "b1", fill = "Frequency") +
theme_classic() +
theme(
strip.background = element_rect(fill = "lightgray"),
strip.text = element_text(face = "bold", size = 12)
)
}
# Create the heatmaps
best_plot <- create_faceted_heatmap(freq_best, "Best Parameters Frequency")
new_plot <- create_faceted_heatmap(freq_new, "New Parameters Frequency")
# Save the plots to separate files
best_plot_fname <- file.path(plot_dir, '3_Regularize', 'G_variance', 'HRF_regularize_plots',
paste0(sess_g, '_best_params_heatmap.png'))
new_plot_fname <- file.path(plot_dir, '3_Regularize', 'G_variance', 'HRF_regularize_plots',
paste0( sess_g, '_new_params_heatmap.png'))
# Create directories if they don't exist
if (!dir.exists(dirname(best_plot_fname))) {
dir.create(dirname(best_plot_fname), recursive = TRUE, showWarnings = FALSE)
}
# Save plots with appropriate dimensions
ggsave(best_plot_fname, best_plot, width = 10, height = 8, dpi = 300)
ggsave(new_plot_fname, new_plot, width = 10, height = 8, dpi = 300)
}
}
}
library(ciftiTools)
ciftiTools.setOption('wb_path','~/') #re-define wb_path because this code is run locally
#library(devtools)
#install_github('mandymejia/templateICAr')
library(templateICAr)
help("templateICAr")
devtools::install_github("mandymejia/templateICAr", "10.0")
remotes::install_github("mandymejia/templateICAr", force = TRUE)
#library(devtools)
#install_github('mandymejia/templateICAr')
library(templateICAr)
library(ciftiTools)
ciftiTools.setOption('wb_path','~/') #re-define wb_path because this code is run locally
#library(devtools)
#install_github('mandymejia/templateICAr')
library(templateICAr)
main_dir <- '~/Documents/Github/FC-TemplateICA-paper'
result_dir <- '	/N/project/FCTemplateICA' #Slate directory to store results
github_results <- file.path(main_dir, 'results')
plot_dir <- file.path(main_dir, 'plots')
setwd(main_dir)
data_directory <- "/N/project/hcp_dcwan"
#list of subjects
subfolders <- list.dirs(data_directory, full.names = FALSE, recursive = FALSE)
subjects <- subfolders[grepl("^\\d{6}$", subfolders)]
N <- length(subjects)
#pick ICs to generate TCs
GICA_fname <- '~/Documents/Github/FC-TemplateICA-paper/data/melodic_IC_25.dscalar.nii'
GICA <- as.matrix(read_cifti(GICA_fname))
ICs <- c(1, 3, 4, 2, 16) #three visual ICs, 1 DMN, 1 motor
L <- length(ICs)
#file path to all subjects
cifti_fullnames <- file.path(data_directory, subjects, "MNINonLinear", "Results", "rfMRI_REST1_LR", "rfMRI_REST1_LR_Atlas.dtseries.nii")
Amats <- array(dim=c(1200, L, N))
for(ii in 1:N){
if(!file.exists(cifti_fullnames[ii])) next()
print(ii)
BOLD_ii <- as.matrix(read_cifti(cifti_fullnames[ii]))
if(ncol(BOLD_ii) != 1200) next()
DR_ii <- templateICAr:::dual_reg(BOLD_ii, GICA, detrend_DCT=10)
Amats[,,ii] <- DR_ii$A[,ICs]
if(ii/100 == round(ii/100)) {
print('saving')
saveRDS(Amats, "~/Documents/Github/FC-TemplateICA-paper/results/TCs.RDS")
}
}
remove.packages("templateICAr")
### This code generates dual regression-based time courses for FC template ICA simulation study
library(ciftiTools)
library(fMRItools)
ciftiTools.setOption('wb_path','~/') #re-define wb_path because this code is run locally
#library(devtools)
#install_github('mandymejia/templateICAr')
library(templateICAr)
main_dir <- '~/Documents/Github/FC-TemplateICA-paper'
result_dir <- '	/N/project/FCTemplateICA' #Slate directory to store results
github_results <- file.path(main_dir, 'results')
plot_dir <- file.path(main_dir, 'plots')
setwd(main_dir)
data_directory <- "/N/project/hcp_dcwan"
#list of subjects
subfolders <- list.dirs(data_directory, full.names = FALSE, recursive = FALSE)
subjects <- subfolders[grepl("^\\d{6}$", subfolders)]
N <- length(subjects)
#pick ICs to generate TCs
GICA_fname <- '~/Documents/Github/FC-TemplateICA-paper/data/melodic_IC_25.dscalar.nii'
GICA <- as.matrix(read_cifti(GICA_fname))
ICs <- c(1, 3, 4, 2, 16) #three visual ICs, 1 DMN, 1 motor
L <- length(ICs)
#file path to all subjects
cifti_fullnames <- file.path(data_directory, subjects, "MNINonLinear", "Results", "rfMRI_REST1_LR", "rfMRI_REST1_LR_Atlas.dtseries.nii")
Amats <- array(dim=c(1200, L, N))
for(ii in 1:N){
if(!file.exists(cifti_fullnames[ii])) next()
print(ii)
BOLD_ii <- as.matrix(read_cifti(cifti_fullnames[ii]))
if(ncol(BOLD_ii) != 1200) next()
DR_ii <- dual_reg(BOLD_ii, GICA, detrend_DCT=10)
Amats[,,ii] <- DR_ii$A[,ICs]
if(ii/100 == round(ii/100)) {
print('saving')
saveRDS(Amats, "~/Documents/Github/FC-TemplateICA-paper/results/TCs.RDS")
}
}
#library(devtools)
#install_github('mandymejia/templateICAr')
library(templateICAr)
find.package("templateICAr")
